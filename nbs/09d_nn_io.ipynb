{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nn.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0489f95",
   "metadata": {},
   "source": [
    "# NN - IO\n",
    "\n",
    "> IO Utilitites for SAX neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.test import test_eq\n",
    "from pytest import approx, raises\n",
    "\n",
    "import os, sys; sys.stderr = open(os.devnull, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01041a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from sax.nn.core import dense, preprocess\n",
    "from sax.nn.utils import norm\n",
    "from sax.typing_ import ComplexFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626189c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def load_nn_weights_json(path: str) -> Dict[str, ComplexFloat]:\n",
    "    \"\"\"Load json weights from given path\"\"\"\n",
    "    path = os.path.abspath(os.path.expanduser(path))\n",
    "    weights = {}\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as file:\n",
    "            for k, v in json.load(file).items():\n",
    "                _v = jnp.array(v, dtype=float)\n",
    "                assert isinstance(_v, jnp.ndarray)\n",
    "                weights[k] = _v\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa53e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def save_nn_weights_json(weights: Dict[str, ComplexFloat], path: str):\n",
    "    \"\"\"Save json weights to given path\"\"\"\n",
    "    path = os.path.abspath(os.path.expanduser(path))\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\") as file:\n",
    "        _weights = {}\n",
    "        for k, v in weights.items():\n",
    "            v = jnp.atleast_1d(jnp.array(v))\n",
    "            assert isinstance(v, jnp.ndarray)\n",
    "            _weights[k] = v.tolist()\n",
    "        json.dump(_weights, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad70875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_available_sizes(\n",
    "    dirpath: str,\n",
    "    prefix: str,\n",
    "    input_names: Tuple[str, ...],\n",
    "    output_names: Tuple[str, ...],\n",
    ") -> List[Tuple[int, ...]]:\n",
    "    \"\"\"Get all available json weight hidden sizes given filename parameters\n",
    "\n",
    "    > Note: this function does NOT return the input size and the output size \n",
    "      of the neural network. ONLY the hidden sizes are reported. The input \n",
    "      and output sizes can easily be derived from `input_names` (after \n",
    "      preprocessing) and `output_names`.\n",
    "    \"\"\"\n",
    "    all_weightfiles = os.listdir(dirpath)\n",
    "    possible_weightfiles = (\n",
    "        s for s in all_weightfiles if s.endswith(f\"-{'-'.join(output_names)}.json\")\n",
    "    )\n",
    "    possible_weightfiles = (\n",
    "        s\n",
    "        for s in possible_weightfiles\n",
    "        if s.startswith(f\"{prefix}-{'-'.join(input_names)}\")\n",
    "    )\n",
    "    possible_weightfiles = (re.sub(\"[^0-9x]\", \"\", s) for s in possible_weightfiles)\n",
    "    possible_weightfiles = (re.sub(\"^x*\", \"\", s) for s in possible_weightfiles)\n",
    "    possible_weightfiles = (re.sub(\"x[^0-9]*$\", \"\", s) for s in possible_weightfiles)\n",
    "    possible_hidden_sizes = (s.strip() for s in possible_weightfiles if s.strip())\n",
    "    possible_hidden_sizes = (\n",
    "        tuple(hs.strip() for hs in s.split(\"x\") if hs.strip())\n",
    "        for s in possible_hidden_sizes\n",
    "    )\n",
    "    possible_hidden_sizes = (\n",
    "        tuple(int(hs) for hs in s[1:-1]) for s in possible_hidden_sizes if len(s) > 2\n",
    "    )\n",
    "    possible_hidden_sizes = sorted(\n",
    "        possible_hidden_sizes, key=lambda hs: (len(hs), max(hs))\n",
    "    )\n",
    "    return possible_hidden_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d619994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_dense_weights_path(\n",
    "    *sizes: int,\n",
    "    input_names: Optional[Tuple[str, ...]] = None,\n",
    "    output_names: Optional[Tuple[str, ...]] = None,\n",
    "    dirpath: str = \"weights\",\n",
    "    prefix: str = \"dense\",\n",
    "    preprocess=preprocess,\n",
    "):\n",
    "    \"\"\"Create the SAX conventional path for a given weight dictionary\"\"\"\n",
    "    if input_names:\n",
    "        num_inputs = preprocess(*jnp.ones(len(input_names))).shape[0]\n",
    "        sizes = (num_inputs,) + sizes\n",
    "    if output_names:\n",
    "        sizes = sizes + (len(output_names),)\n",
    "    path = os.path.abspath(os.path.join(dirpath, prefix))\n",
    "    if input_names:\n",
    "        path = f\"{path}-{'-'.join(input_names)}\"\n",
    "    if sizes:\n",
    "        path = f\"{path}-{'x'.join(str(s) for s in sizes)}\"\n",
    "    if output_names:\n",
    "        path = f\"{path}-{'-'.join(output_names)}\"\n",
    "    return f\"{path}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_norm_path(\n",
    "    *shape: int,\n",
    "    input_names: Optional[Tuple[str, ...]] = None,\n",
    "    output_names: Optional[Tuple[str, ...]] = None,\n",
    "    dirpath: str = \"norms\",\n",
    "    prefix: str = \"norm\",\n",
    "    preprocess=preprocess,\n",
    "):\n",
    "    \"\"\"Create the SAX conventional path for the normalization constants\"\"\"\n",
    "    if input_names and output_names:\n",
    "        raise ValueError(\n",
    "            \"To get the norm name, one can only specify `input_names` OR `output_names`.\"\n",
    "        )\n",
    "    if input_names:\n",
    "        num_inputs = preprocess(*jnp.ones(len(input_names))).shape[0]\n",
    "        shape = (num_inputs,) + shape\n",
    "    if output_names:\n",
    "        shape = shape + (len(output_names),)\n",
    "    path = os.path.abspath(os.path.join(dirpath, prefix))\n",
    "    if input_names:\n",
    "        path = f\"{path}-{'-'.join(input_names)}\"\n",
    "    if shape:\n",
    "        path = f\"{path}-{'x'.join(str(s) for s in shape)}\"\n",
    "    if output_names:\n",
    "        path = f\"{path}-{'-'.join(output_names)}\"\n",
    "    return f\"{path}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "class _PartialDense:\n",
    "    def __init__(self, weights, x_norm, y_norm, input_names, output_names):\n",
    "        self.weights = weights\n",
    "        self.x_norm = x_norm\n",
    "        self.y_norm = y_norm\n",
    "        self.input_names = input_names\n",
    "        self.output_names = output_names\n",
    "\n",
    "    def __call__(self, *params: ComplexFloat) -> ComplexFloat:\n",
    "        return dense(self.weights, *params, x_norm=self.x_norm, y_norm=self.y_norm)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}{repr(self.input_names)}->{repr(self.output_names)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63025ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_nn_dense(\n",
    "    *sizes: int,\n",
    "    input_names: Optional[Tuple[str, ...]] = None,\n",
    "    output_names: Optional[Tuple[str, ...]] = None,\n",
    "    weightprefix=\"dense\",\n",
    "    weightdirpath=\"weights\",\n",
    "    normdirpath=\"norms\",\n",
    "    normprefix=\"norm\",\n",
    "    preprocess=preprocess,\n",
    ") -> Callable:\n",
    "    \"\"\"Load a pre-trained dense model\"\"\"\n",
    "    weights_path = get_dense_weights_path(\n",
    "        *sizes,\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        prefix=weightprefix,\n",
    "        dirpath=weightdirpath,\n",
    "        preprocess=preprocess,\n",
    "    )\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise ValueError(\"Cannot find weights path for given parameters\")\n",
    "    x_norm_path = get_norm_path(\n",
    "        input_names=input_names,\n",
    "        prefix=normprefix,\n",
    "        dirpath=normdirpath,\n",
    "        preprocess=preprocess,\n",
    "    )\n",
    "    if not os.path.exists(x_norm_path):\n",
    "        raise ValueError(\"Cannot find normalization for input parameters\")\n",
    "    y_norm_path = get_norm_path(\n",
    "        output_names=output_names,\n",
    "        prefix=normprefix,\n",
    "        dirpath=normdirpath,\n",
    "        preprocess=preprocess,\n",
    "    )\n",
    "    if not os.path.exists(x_norm_path):\n",
    "        raise ValueError(\"Cannot find normalization for output parameters\")\n",
    "    weights = load_nn_weights_json(weights_path)\n",
    "    x_norm_dict = load_nn_weights_json(x_norm_path)\n",
    "    y_norm_dict = load_nn_weights_json(y_norm_path)\n",
    "    x_norm = norm(x_norm_dict[\"mean\"], x_norm_dict[\"std\"])\n",
    "    y_norm = norm(y_norm_dict[\"mean\"], y_norm_dict[\"std\"])\n",
    "    partial_dense = _PartialDense(weights, x_norm, y_norm, input_names, output_names)\n",
    "    return partial_dense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sax",
   "language": "python",
   "name": "sax"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
